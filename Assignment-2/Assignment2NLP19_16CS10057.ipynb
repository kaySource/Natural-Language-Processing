{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment2NLP19: POS Tagging on hi-ud.conllu using CRFSuite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReadFile(filename, delimiter) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function reads the file<filename> delimited by<delimiter> in the given format\n",
    "def ReadFile(filename, delimiter):\n",
    "    sentences = []\n",
    "    with open(filename, \"r\") as f:\n",
    "        sentence = []\n",
    "        \n",
    "        for tag in f.readlines()[1:]:\n",
    "            if (tag == \"{}{}\\n\".format(delimiter, delimiter)):\n",
    "                sentences.append(sentence)\n",
    "                sentence = []\n",
    "                continue\n",
    "            fields = tag.strip().split(delimiter)\n",
    "            sentence.append((fields[1].strip('\\\"'), fields[2]))\n",
    "        sentences.append(sentence)\n",
    "        \n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features Chosen:\n",
    "**Word**           - The Word Itself  \n",
    "**Work.Lower()**   - The Word reduced to lowercase  \n",
    "**Word.isTitle()** - Boolean True if first character is in UpperCase  \n",
    "**Word.isUpper()** - Boolean True if all characters of the string are UpperCase  \n",
    "**Word.isDigit()** - Boolean True if all characters of the string are Digits  \n",
    "**Prefix-1**       - Word[0:1]  \n",
    "**Prefix-2**       - Word[0:2]  \n",
    "**Prefix-3**       - Word[0:3]  \n",
    "**Suffix-1**       - Word[-3:0]  \n",
    "**Suffix-2**       - Word[-2:0]  \n",
    "**Suffix-3**       - Word[-1:0]  \n",
    "**has_Hyphen**     - Whether word has hyphen in it  \n",
    "\n",
    "**BOS**               - If Word is the Beginning of the Sentence  \n",
    "**-1:Word.Lower()**   - Previous Word reduced to LowerCase   \n",
    "**-1:Word.isTitle()** - Boolean True if first character of the Previous Word is in UpperCase  \n",
    "**-1:Word.isUpper()** - Boolean True if all characters of the Previous word are UpperCase  \n",
    "\n",
    "**EOS**               - If Word is the End of the Sentence  \n",
    "**+1:Word.Lower()**   - Next Word reduced to LowerCase  \n",
    "**+1:Word.isTitle()** - Boolean True if first character of the Next Word is in UpperCase  \n",
    "**+1:Word.isUpper()** - Boolean True if all characters of the Next word are UpperCase  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WordToFeatures(sentence, index_of_word),   SentenceToFeatures(sentence),    SentenceToLabels(sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function returns the features of a word\n",
    "# Input:  'sentence' <list of tuples(Word, POS_Tag)\n",
    "# Output: dict {\"feature\" : value}\n",
    "def WordToFeatures(sentence, index):\n",
    "    Word = sentence[index][0]\n",
    "    \n",
    "    features = {\n",
    "        'Word':           Word,\n",
    "        'Word.Lower()':   Word.lower(),\n",
    "        'Word.isTitle()': Word.istitle(),\n",
    "        'Word.isUpper()': Word.isupper(),\n",
    "        'Word.isDigit()': Word.isdigit(),\n",
    "        'Prefix-1':       Word[0] if len(Word)>0 else '',\n",
    "        'Prefix-2':       Word[:2] if len(Word)>1 else '',\n",
    "        'Prefix-3':       Word[:3] if len(Word)>2 else '',\n",
    "        'Suffix-1':       Word[-1] if len(Word)>0 else '',\n",
    "        'Suffix-2':       Word[-2:] if len(Word)>1 else '',\n",
    "        'Suffix-3':       Word[-3:] if len(Word)>2 else '',\n",
    "        'has_Hyphen':     '-' in Word,\n",
    "    }\n",
    "    \n",
    "    if (index > 0):\n",
    "        PrevWord = sentence[index-1][0]\n",
    "        features.update({\n",
    "            '-1:Word.Lower()'   : PrevWord.lower(),\n",
    "            '-1:Word.isTitle()' : PrevWord.istitle(),\n",
    "            '-1:Word.isUpper()' : PrevWord.isupper(),\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "\n",
    "    if (index < len(sentence)-1):\n",
    "        NextWord = sentence[index+1][0]\n",
    "        features.update({\n",
    "            '+1:Word.Lower()'   : NextWord.lower(),\n",
    "            '+1:Word.isTitle()' : NextWord.istitle(),\n",
    "            '+1:Word.isUpper()' : NextWord.isupper(),\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "# This function returns the features of each word in a sentence\n",
    "# Input: a 'sentence' <list of tuples(Word, POS_tag)>\n",
    "# Output: a <list of <dict of {\"feature\" : value}>> corresponsing to each word\n",
    "def SentenceToFeatures(sentence):\n",
    "    return [WordToFeatures(sentence, i) for i in range(len(sentence))]\n",
    "\n",
    "\n",
    "# This function returns the labels of each word in a sentence\n",
    "# Input: 'sentence' <list of tuples(Word, POS_tags)>\n",
    "# Output: <list of POS_tags>\n",
    "def SentenceToLabels(sentence):\n",
    "    return [fields[1] for fields in sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_Set   = ReadFile('hi-ud-train.conllu', ',')\n",
    "Test_Set    = ReadFile('hi-ud-test.conllu', '\\t')\n",
    "\n",
    "X_Train     = [SentenceToFeatures(sentence) for sentence in Train_Set]\n",
    "Y_TrainTrue = [SentenceToLabels(sentence) for sentence in Train_Set]\n",
    "\n",
    "X_Test      = [SentenceToFeatures(sentence) for sentence in Test_Set]\n",
    "Y_TestTrue  = [SentenceToLabels(sentence) for sentence in Test_Set]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the Model on the Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_states=None, all_possible_transitions=True,\n",
       "    averaging=None, c=None, c1=0.1, c2=0.1, calibration_candidates=None,\n",
       "    calibration_eta=None, calibration_max_trials=None, calibration_rate=None,\n",
       "    calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
       "    gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=300,\n",
       "    max_linesearch=None, min_freq=None, model_filename=None, num_memories=None,\n",
       "    pa_type=None, period=None, trainer_cls=None, variance=None, verbose=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import metrics\n",
    "\n",
    "Model = sklearn_crfsuite.CRF(\n",
    "    algorithm      = 'lbfgs',\n",
    "    c1             = 0.1,\n",
    "    c2             = 0.1,\n",
    "    max_iterations = 300,\n",
    "    all_possible_transitions = True\n",
    ")\n",
    "Model.fit(X_Train, Y_TrainTrue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Model on the Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          MODEL PREDICTION ON TRAINING DATA          \n",
      "-----------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       1.00      1.00      1.00       570\n",
      "         ADP       1.00      1.00      1.00      1387\n",
      "         ADV       0.97      0.98      0.98       111\n",
      "         AUX       0.98      1.00      0.99       730\n",
      "       CCONJ       0.99      1.00      1.00       150\n",
      "       COMMA       1.00      1.00      1.00       114\n",
      "         DET       1.00      0.99      0.99       231\n",
      "        NOUN       1.00      1.00      1.00      1597\n",
      "         NUM       1.00      1.00      1.00       152\n",
      "        PART       1.00      1.00      1.00       163\n",
      "        PRON       1.00      1.00      1.00       431\n",
      "       PROPN       1.00      1.00      1.00       708\n",
      "       PUNCT       1.00      1.00      1.00       564\n",
      "       SCONJ       0.98      1.00      0.99        61\n",
      "        VERB       1.00      0.98      0.99       640\n",
      "           X       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00      7611\n",
      "   macro avg       1.00      1.00      1.00      7611\n",
      "weighted avg       1.00      1.00      1.00      7611\n",
      "\n",
      "precision:  0.996747164954095\n",
      "recall:     0.996715280515044\n",
      "f1-score:   0.9967145038596102\n",
      "accuracy:   0.996715280515044\n"
     ]
    }
   ],
   "source": [
    "print(\"MODEL PREDICTION ON TRAINING DATA\".center(53))\n",
    "print(\"-\"*53)\n",
    "\n",
    "Y_TrainPredicted = Model.predict(X_Train)\n",
    "\n",
    "print(metrics.flat_classification_report(Y_TrainTrue, Y_TrainPredicted))\n",
    "\n",
    "print('precision: ',  metrics.flat_precision_score(Y_TrainTrue, Y_TrainPredicted, average = 'weighted'))\n",
    "print('recall:    ',  metrics.flat_recall_score(Y_TrainTrue, Y_TrainPredicted, average = 'weighted'))\n",
    "print('f1-score:  ',  metrics.flat_f1_score(Y_TrainTrue, Y_TrainPredicted, average = 'weighted'))\n",
    "print('accuracy:  ',  metrics.flat_accuracy_score(Y_TrainTrue, Y_TrainPredicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Model on the Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           MODEL PREDICTION ON TESTING DATA          \n",
      "-----------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.69      0.74      0.71        94\n",
      "         ADP       0.96      0.98      0.97       309\n",
      "         ADV       0.71      0.48      0.57        21\n",
      "         AUX       0.98      0.96      0.97       139\n",
      "       CCONJ       1.00      1.00      1.00        25\n",
      "         DET       0.82      0.89      0.85        36\n",
      "        NOUN       0.78      0.90      0.83       329\n",
      "         NUM       0.92      0.92      0.92        25\n",
      "        PART       0.97      1.00      0.99        33\n",
      "        PRON       0.92      0.83      0.87        65\n",
      "       PROPN       0.71      0.46      0.56       145\n",
      "       PUNCT       1.00      1.00      1.00       135\n",
      "       SCONJ       0.75      1.00      0.86         3\n",
      "        VERB       0.89      0.87      0.88        99\n",
      "\n",
      "    accuracy                           0.87      1458\n",
      "   macro avg       0.86      0.86      0.86      1458\n",
      "weighted avg       0.87      0.87      0.86      1458\n",
      "\n",
      "precision:  0.8674871455800963\n",
      "recall:     0.869684499314129\n",
      "f1-score:   0.8645350167098824\n",
      "accuracy:   0.869684499314129\n"
     ]
    }
   ],
   "source": [
    "print(\"MODEL PREDICTION ON TESTING DATA\".center(53))\n",
    "print(\"-\"*53)\n",
    "\n",
    "Y_TestPredicted = Model.predict(X_Test)\n",
    "\n",
    "print(metrics.flat_classification_report(Y_TestTrue, Y_TestPredicted))\n",
    "\n",
    "print('precision: ',  metrics.flat_precision_score(Y_TestTrue, Y_TestPredicted, average = 'weighted'))\n",
    "print('recall:    ',  metrics.flat_recall_score(Y_TestTrue, Y_TestPredicted, average = 'weighted'))\n",
    "print('f1-score:  ',  metrics.flat_f1_score(Y_TestTrue, Y_TestPredicted, average = 'weighted'))\n",
    "print('accuracy:  ',  metrics.flat_accuracy_score(Y_TestTrue, Y_TestPredicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### printTransitions(transition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function prints the transition from POS_Tag1 -> POS_Tag2 with its corresponding weight\n",
    "def printTransitions(transitions):\n",
    "    for edge, weight in transitions:\n",
    "        print(\"%-6s =>  %-9s %0.5f\" % (edge[0], edge[1], weight))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Printing the 10 Most Common and Least Common Transtition Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Most Common POS Transition Features:\n",
      "-------------------------------------------\n",
      "VERB   =>  AUX       4.24992\n",
      "PROPN  =>  PROPN     3.52655\n",
      "ADJ    =>  NOUN      3.06800\n",
      "NUM    =>  NOUN      2.47544\n",
      "DET    =>  NOUN      2.22345\n",
      "AUX    =>  AUX       2.13554\n",
      "NOUN   =>  ADP       2.09563\n",
      "PROPN  =>  ADP       2.05048\n",
      "NOUN   =>  VERB      1.77167\n",
      "VERB   =>  SCONJ     1.69359\n",
      "\n",
      "\n",
      "Top 10 Least Common POS Transition Features:\n",
      "--------------------------------------------\n",
      "ADP    =>  CCONJ     -1.24472\n",
      "ADP    =>  AUX       -1.24605\n",
      "AUX    =>  ADP       -1.27069\n",
      "PROPN  =>  AUX       -1.31203\n",
      "DET    =>  CCONJ     -1.34330\n",
      "ADP    =>  COMMA     -1.40946\n",
      "CCONJ  =>  AUX       -1.74072\n",
      "ADJ    =>  PRON      -1.92173\n",
      "ADJ    =>  ADP       -2.21294\n",
      "DET    =>  ADP       -2.41440\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "print(\"Top 10 Most Common POS Transition Features:\")\n",
    "print(\"-\"*43)\n",
    "printTransitions(Counter(Model.transition_features_).most_common(10))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Top 10 Least Common POS Transition Features:\")\n",
    "print(\"-\"*44)\n",
    "printTransitions(Counter(Model.transition_features_).most_common()[-10:])\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
